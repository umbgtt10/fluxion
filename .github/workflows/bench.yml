name: Benchmarks

on:
  workflow_dispatch:      # Manual "Run workflow" button
  push:
    branches: [main]
  pull_request:
  schedule:
    - cron: '0 4 * * *'    # Daily at 4 AM UTC

jobs:
  bench:
    runs-on: ubuntu-latest
    permissions:
      contents: write       # To commit baseline data

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install stable Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry + target
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

      - name: Run all fluxion-stream benchmarks
        run: cargo bench --package fluxion-stream --verbose

      # --------------------------------------------------------------
      # DEBUG: Show what was actually generated
      # --------------------------------------------------------------
      - name: Debug - Show criterion output
        run: |
          echo "=== Checking target/criterion structure ==="
          ls -la target/ || echo "No target directory"
          echo ""
          echo "=== Checking target/criterion ==="
          ls -la target/criterion/ || echo "No criterion directory"
          echo ""
          echo "=== Finding all directories in target/criterion ==="
          find target/criterion -type d 2>/dev/null || echo "No criterion output found"
          echo ""
          echo "=== Finding all JSON files ==="
          find target/criterion -name "*.json" 2>/dev/null || echo "No JSON files"

      # --------------------------------------------------------------
      # 1. ALWAYS create/update baseline from this run (before comparison)
      # --------------------------------------------------------------
      - name: Create/update baseline JSON
        run: |
          mkdir -p benches/baseline/benchmarks

          # The actual path where criterion outputs
          if [ -d "target/criterion/benchmarks" ] && [ "$(ls -A target/criterion/benchmarks 2>/dev/null)" ]; then
            cp -r target/criterion/benchmarks/* benches/baseline/benchmarks/
            echo "Baseline updated from this run"
            git add -A benches/baseline
          else
            echo "No benchmark data generated - skipping baseline update"
            echo "Attempting to find and copy any criterion output..."
            if [ -d "target/criterion" ]; then
              cp -r target/criterion/* benches/baseline/benchmarks/ 2>/dev/null || echo "Copy failed"
            fi
          fi

      # --------------------------------------------------------------
      # 2. Commit baseline (only on main + nightly)
      # --------------------------------------------------------------
      - name: Commit baseline to repo (on main/schedule)
        if: github.ref == 'refs/heads/main' || github.event_name == 'schedule'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update benchmark baseline [ci skip]"
          file_pattern: 'benches/baseline/**'
          commit_user_name: github-actions[bot]
          commit_user_email: github-actions[bot]@users.noreply.github.com
          skip_dirty_check: false
          skip_fetch: false
          skip_checkout: false

      # --------------------------------------------------------------
      # 3. Compare + fail on regressions
      # --------------------------------------------------------------
      - name: Install critcmp
        run: cargo install critcmp --locked

      - name: Regression check (>10% slowdown = fail)
        run: |
          set -euo pipefail

          # Skip if baseline doesn't exist yet (first run)
          if [ ! -d "benches/baseline/benchmarks" ] || [ ! -d "target/criterion/benchmarks" ]; then
            echo "Skipping regression check â€“ baseline not ready"
            echo "First run - baseline will be established" > benches/comparison.txt
            exit 0
          fi

          # Check if there are any actual benchmark results to compare
          if [ ! "$(find benches/baseline/benchmarks -name '*.json' 2>/dev/null)" ]; then
            echo "No baseline data files found yet"
            echo "Baseline is being established" > benches/comparison.txt
            exit 0
          fi

          echo "Running comparison..."
          critcmp benches/baseline/benchmarks target/criterion/benchmarks --threshold 10 > benches/comparison.txt 2>&1 || {
            # Handle "no comparisons" gracefully
            if grep -qi "no benchmark comparisons\|no benchmarks found" benches/comparison.txt; then
              echo "No changes detected (identical to baseline) â€“ all good!"
              echo "No regressions detected" > benches/comparison.txt
              exit 0
            else
              echo "Comparison failed or found regressions:"
              cat benches/comparison.txt
              # Check if it's a regression or just an error
              if grep -qi "SLOWER\|regression" benches/comparison.txt; then
                exit 1
              else
                # Unknown error, but don't fail the build
                echo "Warning: critcmp comparison had issues but no clear regression detected"
                exit 0
              fi
            fi
          }

          cat benches/comparison.txt

          if grep -qi "SLOWER" benches/comparison.txt; then
            echo "ðŸš¨ Performance regression detected!"
            exit 1
          else
            echo "âœ… All benchmarks stable or improved"
          fi

      # --------------------------------------------------------------
      # 4. Upload report
      # --------------------------------------------------------------
      - name: Upload Criterion report
        uses: actions/upload-artifact@v4
        if: always()  # Upload even if regression check fails
        with:
          name: benchmark-report
          path: target/criterion/
          retention-days: 14

      # --------------------------------------------------------------
      # 5. PR comment
      # --------------------------------------------------------------
      - name: Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let comparison = 'Comparison skipped (first run or no changes detected).';
            if (fs.existsSync('benches/comparison.txt')) {
              comparison = fs.readFileSync('benches/comparison.txt', 'utf8').trim();
            }

            const runUrl = process.env.GITHUB_SERVER_URL + '/' + process.env.GITHUB_REPOSITORY + '/actions/runs/' + process.env.GITHUB_RUN_ID + '/artifacts';
            const body = '### ðŸ“Š Benchmark Results (fluxion-stream)\n\n' +
                         '```\n' + comparison + '\n```\n\n' +
                         'ðŸ“ˆ Full interactive report (HTML tables + graphs): [Download benchmark-report artifact](' + runUrl + ')';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body.trim()
            });
